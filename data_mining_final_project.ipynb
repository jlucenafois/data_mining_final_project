{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### **Part 0: Preprocessing** - Import dependencies, define aliases, clean data, normalize clinic names, and create utility functions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from rapidfuzz import process\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "# import spacy\n",
    "\n",
    "# # Load SpaCy model\n",
    "# nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aliases for filenames  \n",
    "DATA_FILENAME = 'data.csv'\n",
    "CLINICS_IN_RED_FILENAME = 'clinics.json'\n",
    "TIER_COMPARISON_FILENAME = 'tier_comparison.json'\n",
    "\n",
    "# aliases for relevant columns\n",
    "ALIASES = {\n",
    "    'CONCATENADO': 'ID',\n",
    "    'Clinica1': 'CLINIC',\n",
    "    'fe_declaracion': 'DATE',\n",
    "    'procedimiento': 'PROCEDURE',\n",
    "    'estatus_siniestro1': 'STATUS',\n",
    "    'pais': 'COUNTRY',\n",
    "    'Region': 'REGION',\n",
    "    'tipo_siniestro1': 'TYPE',\n",
    "    'monto usd': 'PAID_USD',\n",
    "    'SA': 'INSURANCE_COVERAGE',\n",
    "    'enfermedad1': 'CONDITION',\n",
    "    'tipo_proc': 'PROCEDURE_TYPE',\n",
    "    'Rango edad': 'AGE_RANGE'\n",
    "}\n",
    "\n",
    "# type definitions for relevant columns\n",
    "DATA_TYPE_DICT = {\n",
    "    'CONCATENADO': 'object',\n",
    "    'Clinica1': 'object',\n",
    "    'fe_declaracion': 'object',\n",
    "    'procedimiento': 'object',\n",
    "    'estatus_siniestro1': 'object',\n",
    "    'pais': 'object',\n",
    "    'Region': 'object',\n",
    "    'tipo_siniestro1': 'object',\n",
    "    'monto usd': 'object',  # Changed from float64 to object\n",
    "    'SA': 'object',         # Changed from float64 to object\n",
    "    'enfermedad1': 'object',\n",
    "    'tipo_proc': 'object',\n",
    "    'Rango edad': 'object'\n",
    "}\n",
    "\n",
    "# format floats\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read utils \n",
    "def df_data(filename): \n",
    "    \"\"\"\n",
    "    Reads .csv file and returns DataFrame with relevant columns.\n",
    "    Now includes data cleaning for numeric columns.\n",
    "    \"\"\"\n",
    "    # First, read the CSV without dtype specifications to see actual columns\n",
    "    df = pd.read_csv(filename, encoding='utf-8', low_memory=False)\n",
    "    \n",
    "    # Print actual columns to help debug\n",
    "    print(\"Available columns in CSV:\", df.columns.tolist())\n",
    "    \n",
    "    # Create a mapping of available columns to their dtypes\n",
    "    available_dtypes = {col: DATA_TYPE_DICT[col] for col in DATA_TYPE_DICT if col in df.columns}\n",
    "    \n",
    "    # Read again with correct dtypes\n",
    "    df = pd.read_csv(filename, dtype=available_dtypes, encoding='utf-8', low_memory=False)\n",
    "    \n",
    "    # Select only the columns that exist\n",
    "    existing_columns = [col for col in DATA_TYPE_DICT if col in df.columns]\n",
    "    if not existing_columns:\n",
    "        raise ValueError(\"None of the specified columns found in the CSV file!\")\n",
    "    \n",
    "    df = df[existing_columns]\n",
    "    \n",
    "    # Clean numeric columns\n",
    "    # Replace '-' with NaN and convert to float\n",
    "    if 'monto usd' in df.columns:\n",
    "        df['monto usd'] = pd.to_numeric(df['monto usd'].replace('-', np.nan), errors='coerce')\n",
    "    if 'SA' in df.columns:\n",
    "        df['SA'] = pd.to_numeric(df['SA'].replace('-', np.nan), errors='coerce')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def json_data(filename): \n",
    "    \"\"\"\n",
    "    Reads filename and returns json object. \n",
    "    \"\"\"      \n",
    "    with open(filename) as file:\n",
    "        return json.load(file)\n",
    "# transform utils\n",
    "\n",
    "def normalized(df, column, reference, threshold=90):\n",
    "    \"\"\"\n",
    "    Normalizes a column given a reference name using closest matches. \n",
    "    Fixes inconsistent entries that refer to the same value.\n",
    "    Matches only apply if the confidence score is above the given threshold.\n",
    "    Displays the number of unique clinic names before and after normalization.\n",
    "    Prints which names were normalized.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Count unique values before normalization\n",
    "    unique_before = df[column].nunique()\n",
    "\n",
    "    # Create the mapping with confidence filtering\n",
    "    mapping = {}\n",
    "    normalized_log = []  # Track normalized entries\n",
    "    for clinic in df[column].unique():\n",
    "        match = process.extractOne(clinic, reference)\n",
    "        if match and match[1] >= threshold:  # Check confidence score\n",
    "            normalized_name = match[0]\n",
    "            if clinic != normalized_name:\n",
    "                normalized_log.append((clinic, normalized_name))  # Log changes\n",
    "            mapping[clinic] = normalized_name\n",
    "        else:\n",
    "            mapping[clinic] = clinic  # Retain original name if confidence is low\n",
    "\n",
    "    # Normalize the column\n",
    "    df[column] = df[column].map(mapping)\n",
    "\n",
    "    # Count unique values after normalization\n",
    "    unique_after = df[column].nunique()\n",
    "\n",
    "    # Print unique counts\n",
    "    print(f\"Unique clinic names before normalization: {unique_before}\")\n",
    "    print(f\"Unique clinic names after normalization: {unique_after}\")\n",
    "\n",
    "    # Print what names were normalized\n",
    "    if normalized_log:\n",
    "        print(\"\\nNormalized Names:\")\n",
    "        for original, normalized in normalized_log:\n",
    "            print(f\"  {original} -> {normalized}\")\n",
    "    else:\n",
    "        print(\"\\nNo names were normalized.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in CSV: ['sucursal', 'ramo', 'poliza', 'de_motivo_siniestro', 'causa_siniestro', 'cd_pais', 'cd_usuario', 'siniestro', 'tipo_siniestro', 'estatus_siniestro', 'facturado', 'monto_usd', 'fe_ocurrencia', 'fe_declaracion', 'enfermedad', 'procedimiento', 'especialidad', 'tratamiento', 'nombre_afectado', 'cedula_afectado', 'edad', 'concepto', 'rif_contratante', 'contratante', 'cd_mediador', 'nm_mediador', 'estado', 'rif_clin', 'clinica', 'tipo_proveedor', 'fe_ingreso', 'fe_egreso', 'pais', 'ciudad', 'conexion', 'localidad', 'monto usd', 'tipo_siniestro1', 'CONCATENADO', 'Mes', 'Año', 'Region', 'Ocurrencia', 'estatus_siniestro1', 'tipo de poliza', 'tipo_proc', 'Rango edad', 'Proveedor Internacional', 'Categoría', 'SA', 'Producto', 'Clinica1', 'enfermedad1', 'tasa ocurrencia', 'Facturado_usd', 'desglose1']\n",
      "Unique clinic names before normalization: 231\n",
      "Unique clinic names after normalization: 228\n",
      "\n",
      "Normalized Names:\n",
      "  POLICLINICA LA ARBOLEDA, C.A -> POLICLINICA LA ARBOLEDA, C.A.\n",
      "  INSTITUTO CLINICO LA FLORIDA C.A -> INSTITUTO CLINICO LA FLORIDA, C.A.\n",
      "  CLINICA SANATRIX C.A -> CLINICA SANATRIX, C.A.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CLINIC</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PROCEDURES</th>\n",
       "      <th>PAID_USD</th>\n",
       "      <th>IN_RED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00673554EMBARAZO, PARTO Y PUERPERIOoctubre2023...</td>\n",
       "      <td>HOSPITAL DE CLINICAS CARACAS, C.A.</td>\n",
       "      <td>EMERGENCIA</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>[TRATAMIENTO MEDICO CON PROCEDIMIENTO NO BAREM...</td>\n",
       "      <td>5684.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00673554NAUSEA Y VOMITOabril2023EMERGENCIA</td>\n",
       "      <td>HOSPITAL DE CLINICAS CARACAS, C.A.</td>\n",
       "      <td>EMERGENCIA</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>[TRATAMIENTO MEDICO AMBULATORIO, TRATAMIENTO M...</td>\n",
       "      <td>633.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>069701191TRAUMATISMO SUPERFICIAL DE LA CADERA ...</td>\n",
       "      <td>A.C. CENTRO MEDICO DOCENTE LA TRINIDAD</td>\n",
       "      <td>EMERGENCIA</td>\n",
       "      <td>2023-07-26</td>\n",
       "      <td>[ Esguince Tobillo]</td>\n",
       "      <td>1873.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>091139498FRACTURAS QUE AFECTAN MULTIPLES REGIO...</td>\n",
       "      <td>INTERVERTEBRA C.A.</td>\n",
       "      <td>EMERGENCIA</td>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>[TRATAMIENTO MEDICO CON HOSPITALIZACION]</td>\n",
       "      <td>7095.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>099809108TRAUMATISMO SUPERFICIAL DE LA CADERA ...</td>\n",
       "      <td>GRUPO MEDICO SANTA PAULA, S.A. (GMSP S.A.)</td>\n",
       "      <td>EMERGENCIA</td>\n",
       "      <td>2024-03-05</td>\n",
       "      <td>[ Esguince Tobillo,  Esguince Tobillo]</td>\n",
       "      <td>805.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID  \\\n",
       "0  00673554EMBARAZO, PARTO Y PUERPERIOoctubre2023...   \n",
       "1         00673554NAUSEA Y VOMITOabril2023EMERGENCIA   \n",
       "2  069701191TRAUMATISMO SUPERFICIAL DE LA CADERA ...   \n",
       "3  091139498FRACTURAS QUE AFECTAN MULTIPLES REGIO...   \n",
       "4  099809108TRAUMATISMO SUPERFICIAL DE LA CADERA ...   \n",
       "\n",
       "                                       CLINIC        TYPE       DATE  \\\n",
       "0          HOSPITAL DE CLINICAS CARACAS, C.A.  EMERGENCIA 2023-10-30   \n",
       "1          HOSPITAL DE CLINICAS CARACAS, C.A.  EMERGENCIA 2023-04-09   \n",
       "2      A.C. CENTRO MEDICO DOCENTE LA TRINIDAD  EMERGENCIA 2023-07-26   \n",
       "3                          INTERVERTEBRA C.A.  EMERGENCIA 2023-05-13   \n",
       "4  GRUPO MEDICO SANTA PAULA, S.A. (GMSP S.A.)  EMERGENCIA 2024-03-05   \n",
       "\n",
       "                                          PROCEDURES  PAID_USD  IN_RED  \n",
       "0  [TRATAMIENTO MEDICO CON PROCEDIMIENTO NO BAREM...  5684.000   False  \n",
       "1  [TRATAMIENTO MEDICO AMBULATORIO, TRATAMIENTO M...   633.000   False  \n",
       "2                                [ Esguince Tobillo]  1873.000   False  \n",
       "3           [TRATAMIENTO MEDICO CON HOSPITALIZACION]  7095.000   False  \n",
       "4             [ Esguince Tobillo,  Esguince Tobillo]   805.000   False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read json files as dictionaries\n",
    "CLINICS_IN_RED = json_data(CLINICS_IN_RED_FILENAME) # clinic to joined_dates and tier\n",
    "TIER_COMPARSION = json_data(TIER_COMPARISON_FILENAME) # comparison clinics for each tier\n",
    "\n",
    "def in_red(entry): \n",
    "    \"\"\"\n",
    "    Determines if an entry was handled in red. \n",
    "    True if: \n",
    "        1. Clinic is in red for entry's type and \n",
    "        2. Entry happened on or after the clinic joined the red for entry's type\n",
    "    False otherwise.    \n",
    "    \"\"\" \n",
    "    clinic = entry['CLINIC']\n",
    "    type = entry['TYPE']\n",
    "    date = entry['DATE']\n",
    "    if clinic not in CLINICS_IN_RED or type not in CLINICS_IN_RED[clinic]['join_date']:\n",
    "        return False\n",
    "    join_date = datetime.strptime(\n",
    "        CLINICS_IN_RED[clinic]['join_date'][type], '%m/%d/%Y')\n",
    "    if date < join_date:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# read\n",
    "df = df_data(DATA_FILENAME)\n",
    "\n",
    "# rename\n",
    "df.rename(columns=ALIASES, inplace=True)\n",
    "\n",
    "# filter\n",
    "df_filtered = df[\n",
    "    (df[\"STATUS\"] == \"CERRADO\") & \n",
    "    (df[\"REGION\"] == \"Caracas\") & \n",
    "    (df[\"TYPE\"].isin([\"EMERGENCIA\", \"CARTA AVAL\"]))\n",
    "]\n",
    "\n",
    "# transform dates to datetime objects\n",
    "df_filtered['DATE'] = pd.to_datetime(\n",
    "        df_filtered['DATE'], format='%m/%d/%Y')\n",
    "\n",
    "# normalize\n",
    "standard_clinic_names = set(CLINICS_IN_RED.keys()) | set(\n",
    "    c for t in TIER_COMPARSION.keys() for c in TIER_COMPARSION[t]\n",
    ")\n",
    "df_normalized = normalized(df_filtered, \"CLINIC\", standard_clinic_names)\n",
    "\n",
    "# aggregate by ID, CLINIC, and TYPE\n",
    "df_aggregated = df_normalized.groupby([\"ID\", \"CLINIC\", \"TYPE\"]).agg({\n",
    "    'DATE': 'min',  # Earliest and latest dates\n",
    "    'PROCEDURE': list,       # List of procedures\n",
    "    'PAID_USD': 'sum',       # Sum of payments\n",
    "}).reset_index()\n",
    "\n",
    "# flatten multi-level column names\n",
    "df_aggregated.columns = ['ID', 'CLINIC', 'TYPE', 'DATE', 'PROCEDURES', 'PAID_USD']\n",
    "\n",
    "# classify\n",
    "df_aggregated[\"IN_RED\"] = df_aggregated.apply(in_red, axis=1)\n",
    "\n",
    "# save to CSV\n",
    "df_aggregated.to_csv('data_clean.csv', index=False)\n",
    "\n",
    "# display the result\n",
    "df_aggregated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_procedures(procedures):\n",
    "    \"\"\"Groups similar procedures using NLP\"\"\"\n",
    "    \n",
    "    # Preprocess procedures - convert all items to strings and filter out non-string values\n",
    "    proc_texts = []\n",
    "    for proc_list in procedures:\n",
    "        # Convert all items to strings and filter out None/NaN\n",
    "        clean_procs = [str(p) for p in proc_list if p is not None and pd.notna(p)]\n",
    "        if clean_procs:  # Only join if there are valid procedures\n",
    "            proc_texts.append(' '.join(clean_procs))\n",
    "        else:\n",
    "            proc_texts.append('')  # Empty string for invalid procedures\n",
    "    \n",
    "    # Create TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=1000  # Limit features to most important ones\n",
    "    )\n",
    "    \n",
    "    # Handle empty case\n",
    "    if not proc_texts or all(text == '' for text in proc_texts):\n",
    "        return {}\n",
    "    \n",
    "    vectors = vectorizer.fit_transform(proc_texts)\n",
    "    \n",
    "    # Cluster procedures\n",
    "    n_clusters = min(len(proc_texts) // 10, 50)  # Reasonable number of clusters\n",
    "    n_clusters = max(n_clusters, 1)  # Ensure at least 1 cluster\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(vectors)\n",
    "    \n",
    "    # Create mapping of procedures to clusters\n",
    "    proc_clusters = {}\n",
    "    for proc, cluster in zip(procedures, clusters):\n",
    "        proc_key = tuple(str(p) for p in proc if p is not None and pd.notna(p))  # Make procedure list hashable\n",
    "        if proc_key:  # Only add if there are valid procedures\n",
    "            proc_clusters[proc_key] = cluster\n",
    "            \n",
    "    return proc_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1: Descriptive Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1.1: Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of claims: 47,427\n",
      "Date range: 01/01/2023 to 05/30/2024\n",
      "Number of unique clinics: 228\n",
      "Number of unique procedures: 459\n",
      "\n",
      "Total amount paid (USD): $135,670,167.00\n",
      "Average claim amount (USD): $2,860.61\n",
      "Median claim amount (USD): $1,370.00\n",
      "Top 10 Clinics by Number of Claims:\n",
      "\n",
      "A.C. CENTRO MEDICO DOCENTE LA TRINIDAD\n",
      "  Claims: 5,228\n",
      "  Total Amount: $19,584,993.00\n",
      "  Average Amount: $3,746.17\n",
      "\n",
      "POLICLINICA METROPOLITANA, C.A.\n",
      "  Claims: 3,945\n",
      "  Total Amount: $15,311,877.00\n",
      "  Average Amount: $3,881.34\n",
      "\n",
      "CLINICA SANTIAGO DE LEON, C.A.\n",
      "  Claims: 3,087\n",
      "  Total Amount: $7,261,662.00\n",
      "  Average Amount: $2,352.34\n",
      "\n",
      "CLINICA EL AVILA, C.A.\n",
      "  Claims: 3,043\n",
      "  Total Amount: $7,722,080.00\n",
      "  Average Amount: $2,537.65\n",
      "\n",
      "GRUPO MEDICO SANTA PAULA, S.A. (GMSP S.A.)\n",
      "  Claims: 2,588\n",
      "  Total Amount: $8,760,369.00\n",
      "  Average Amount: $3,385.00\n",
      "\n",
      "VENEURGENCIAS C.A\n",
      "  Claims: 2,452\n",
      "  Total Amount: $768,860.00\n",
      "  Average Amount: $313.56\n",
      "\n",
      "CENTRO CLINICO FENIX SALUD,C.A.\n",
      "  Claims: 1,693\n",
      "  Total Amount: $4,264,339.00\n",
      "  Average Amount: $2,518.81\n",
      "\n",
      "CLINICA SANATRIX, C.A.\n",
      "  Claims: 1,435\n",
      "  Total Amount: $5,216,521.00\n",
      "  Average Amount: $3,635.21\n",
      "\n",
      "CENTRO MEDICO LOIRA, C.A.\n",
      "  Claims: 1,426\n",
      "  Total Amount: $3,458,602.00\n",
      "  Average Amount: $2,425.39\n",
      "\n",
      "C.A. CENTRO MEDICO DE CARACAS\n",
      "  Claims: 1,248\n",
      "  Total Amount: $6,070,198.00\n",
      "  Average Amount: $4,863.94\n"
     ]
    }
   ],
   "source": [
    "### Part 1: Descriptive Analysis\n",
    "\n",
    "# Basic dataset statistics\n",
    "print(f\"Total number of claims: {len(df_aggregated):,}\")\n",
    "print(f\"Date range: {df_aggregated['DATE'].min().strftime('%m/%d/%Y')} to {df_aggregated['DATE'].max().strftime('%m/%d/%Y')}\")\n",
    "print(f\"Number of unique clinics: {df_aggregated['CLINIC'].nunique():,}\")\n",
    "print(f\"Number of unique procedures: {df_normalized['PROCEDURE'].nunique():,}\")\n",
    "print(f\"\\nTotal amount paid (USD): ${df_aggregated['PAID_USD'].sum():,.2f}\")\n",
    "print(f\"Average claim amount (USD): ${df_aggregated['PAID_USD'].mean():,.2f}\")\n",
    "print(f\"Median claim amount (USD): ${df_aggregated['PAID_USD'].median():,.2f}\")\n",
    "\n",
    "\n",
    "top_clinics = df_aggregated['CLINIC'].value_counts().head(10)\n",
    "print(\"Top 10 Clinics by Number of Claims:\")\n",
    "for clinic, count in top_clinics.items():\n",
    "    total_amount = df_aggregated[df_aggregated['CLINIC'] == clinic]['PAID_USD'].sum()\n",
    "    avg_amount = df_aggregated[df_aggregated['CLINIC'] == clinic]['PAID_USD'].mean()\n",
    "    print(f\"\\n{clinic}\")\n",
    "    print(f\"  Claims: {count:,}\")\n",
    "    print(f\"  Total Amount: ${total_amount:,.2f}\")\n",
    "    print(f\"  Average Amount: ${avg_amount:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 13 Procedures (first 3 are too broad to categorize):\n",
      "\n",
      "TRATAMIENTO MEDICO AMBULATORIO\n",
      "  Claims: 35,606\n",
      "  Total Amount: $21,998,432.00\n",
      "  Average Amount: $617.83\n",
      "\n",
      "TRATAMIENTO MEDICO CON HOSPITALIZACION\n",
      "  Claims: 21,065\n",
      "  Total Amount: $38,142,437.00\n",
      "  Average Amount: $1,810.70\n",
      "\n",
      "TRATAMIENTO MEDICO CON PROCEDIMIENTO NO BAREMIZADO\n",
      "  Claims: 4,301\n",
      "  Total Amount: $12,603,069.00\n",
      "  Average Amount: $2,930.26\n",
      "\n",
      "Cesárea\n",
      "  Claims: 1,973\n",
      "  Total Amount: $4,102,508.00\n",
      "  Average Amount: $2,079.32\n",
      "\n",
      "Facomulsificación + LIO\n",
      "  Claims: 1,686\n",
      "  Total Amount: $1,650,476.00\n",
      "  Average Amount: $978.93\n",
      "\n",
      "Facoemulsificación de Catarata con Implante de LIO Monofocal\n",
      "  Claims: 1,016\n",
      "  Total Amount: $1,058,181.00\n",
      "  Average Amount: $1,041.52\n",
      "\n",
      "Colecistectomia Laparoscopica\n",
      "  Claims: 900\n",
      "  Total Amount: $2,186,484.00\n",
      "  Average Amount: $2,429.43\n",
      "\n",
      " Esguince Tobillo\n",
      "  Claims: 586\n",
      "  Total Amount: $349,600.00\n",
      "  Average Amount: $596.59\n",
      "\n",
      "Apendicectomía Laparoscópica\n",
      "  Claims: 417\n",
      "  Total Amount: $1,140,762.00\n",
      "  Average Amount: $2,735.64\n",
      "\n",
      "CIRUGIA FUNCIONAL ENDOSCOPICA DE DE LOS  SENO PARANASALES (FESS)+ TURBINECTOMIA\n",
      "  Claims: 326\n",
      "  Total Amount: $852,976.00\n",
      "  Average Amount: $2,616.49\n",
      "\n",
      "Administración de quimioterapia, intravenoso; técnica infusión, una a 8 horas, cada hora adicional\n",
      "  Claims: 318\n",
      "  Total Amount: $777,224.00\n",
      "  Average Amount: $2,444.10\n",
      "\n",
      "Histerectomia Total Abdominal\n",
      "  Claims: 300\n",
      "  Total Amount: $852,209.00\n",
      "  Average Amount: $2,840.70\n",
      "\n",
      "CIR. FUNCIONAL ENDONASAL(CFE)+CIR. FUNCIONAL ENDOSCOPIA SENOS PARANASALES ( FESS)  + AMIGDALECTOMIA O ADENOIDECTOMIA\n",
      "  Claims: 286\n",
      "  Total Amount: $729,728.00\n",
      "  Average Amount: $2,551.50\n"
     ]
    }
   ],
   "source": [
    "# Top 10 procedures\n",
    "top_procedures = df_normalized['PROCEDURE'].value_counts().head(13)\n",
    "print(\"Top 13 Procedures (first 3 are too broad to categorize):\")\n",
    "for procedure, count in top_procedures.items():\n",
    "    total_amount = df_normalized[df_normalized['PROCEDURE'] == procedure]['PAID_USD'].sum()\n",
    "    avg_amount = df_normalized[df_normalized['PROCEDURE'] == procedure]['PAID_USD'].mean()\n",
    "    print(f\"\\n{procedure}\")\n",
    "    print(f\"  Claims: {count:,}\")\n",
    "    print(f\"  Total Amount: ${total_amount:,.2f}\")\n",
    "    print(f\"  Average Amount: ${avg_amount:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network vs Non-Network Statistics:\n",
      "\n",
      "In-Network:\n",
      "  Number of Claims: 1,974\n",
      "  Total Amount: $5,817,076.00\n",
      "  Average Amount: $2,946.85\n",
      "  Median Amount: $1,485.50\n",
      "\n",
      "Out-of-Network:\n",
      "  Number of Claims: 45,453\n",
      "  Total Amount: $129,853,091.00\n",
      "  Average Amount: $2,856.87\n",
      "  Median Amount: $1,365.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_140251/3712268490.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  in_red_stats = df_aggregated.groupby('IN_RED').agg({\n"
     ]
    }
   ],
   "source": [
    "# Network statistics\n",
    "df_aggregated['IN_RED'] = df_aggregated['IN_RED'].astype('category')  # Convert to category\n",
    "in_red_stats = df_aggregated.groupby('IN_RED').agg({\n",
    "    'ID': 'count',\n",
    "    'PAID_USD': ['sum', 'mean', 'median']\n",
    "}).round(2)\n",
    "\n",
    "print(\"Network vs Non-Network Statistics:\")\n",
    "for network_status in [True, False]:\n",
    "    status_label = \"In-Network\" if network_status else \"Out-of-Network\"\n",
    "    subset = df_aggregated[df_aggregated['IN_RED'] == network_status]\n",
    "    \n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{status_label}:\")\n",
    "        print(f\"  Number of Claims: {len(subset):,}\")\n",
    "        print(f\"  Total Amount: ${subset['PAID_USD'].sum():,.2f}\")\n",
    "        print(f\"  Average Amount: ${subset['PAID_USD'].mean():,.2f}\")\n",
    "        print(f\"  Median Amount: ${subset['PAID_USD'].median():,.2f}\")\n",
    "    else:\n",
    "        print(f\"\\n{status_label}: No claims found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Trends (Last 6 months):\n",
      "\n",
      "December 2023:\n",
      "  Claims: 2,996.0\n",
      "  Total Amount: $6,921,204.00\n",
      "  Average Amount: $2,310.15\n",
      "\n",
      "January 2024:\n",
      "  Claims: 2,744.0\n",
      "  Total Amount: $6,344,332.00\n",
      "  Average Amount: $2,312.07\n",
      "\n",
      "February 2024:\n",
      "  Claims: 2,272.0\n",
      "  Total Amount: $5,484,953.00\n",
      "  Average Amount: $2,414.15\n",
      "\n",
      "March 2024:\n",
      "  Claims: 2,326.0\n",
      "  Total Amount: $5,385,472.00\n",
      "  Average Amount: $2,315.34\n",
      "\n",
      "April 2024:\n",
      "  Claims: 1,345.0\n",
      "  Total Amount: $3,546,887.00\n",
      "  Average Amount: $2,637.09\n",
      "\n",
      "May 2024:\n",
      "  Claims: 367.0\n",
      "  Total Amount: $1,132,712.00\n",
      "  Average Amount: $3,086.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_140251/1666088642.py:2: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_trends = df_aggregated.set_index('DATE').resample('M').agg({\n"
     ]
    }
   ],
   "source": [
    "# Monthly trends\n",
    "monthly_trends = df_aggregated.set_index('DATE').resample('M').agg({\n",
    "    'ID': 'count',\n",
    "    'PAID_USD': ['sum', 'mean']\n",
    "}).round(2)\n",
    "\n",
    "print(\"Monthly Trends (Last 6 months):\")\n",
    "for date, stats in monthly_trends.tail(6).iterrows():\n",
    "    print(f\"\\n{date.strftime('%B %Y')}:\")\n",
    "    print(f\"  Claims: {stats['ID']['count']:,}\")\n",
    "    print(f\"  Total Amount: ${stats['PAID_USD']['sum']:,.2f}\")\n",
    "    print(f\"  Average Amount: ${stats['PAID_USD']['mean']:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n",
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n",
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n",
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n",
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n",
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n",
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n",
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n",
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n",
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n",
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n",
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clinic Performance Analysis After Joining Network\n",
      "--------------------------------------------------\n",
      "\n",
      "Overperformer Clinics (4):\n",
      "\n",
      "  CENTRO CLINICO FENIX SALUD,C.A. (Tier C):\n",
      "    Claims Volume: +16.7%\n",
      "    Monthly Claims: +16.7%\n",
      "    Median Price: -21.6%\n",
      "    Mean Price: -11.3%\n",
      "    Procedures per Claim: +6.1%\n",
      "\n",
      "  CENTRO CLINICO VISTA CALIFORNIA, C.A. (Tier C):\n",
      "    Claims Volume: +217.4%\n",
      "    Monthly Claims: +217.4%\n",
      "    Median Price: +17.4%\n",
      "    Mean Price: -12.0%\n",
      "    Procedures per Claim: +13.7%\n",
      "\n",
      "  GRUPO MEDICO LAS ACACIAS, C.A. (Tier B):\n",
      "    Claims Volume: +168.8%\n",
      "    Monthly Claims: +168.8%\n",
      "    Median Price: -54.4%\n",
      "    Mean Price: -37.9%\n",
      "    Procedures per Claim: +1.8%\n",
      "\n",
      "  SERVICIOS CLINICOS SANTA MONICA, C.A. (Tier B):\n",
      "    Claims Volume: +13.2%\n",
      "    Monthly Claims: +13.2%\n",
      "    Median Price: -9.9%\n",
      "    Mean Price: -23.6%\n",
      "    Procedures per Claim: +5.0%\n",
      "\n",
      "As Expected Clinics (6):\n",
      "\n",
      "  A.C. CENTRO MEDICO DOCENTE LA TRINIDAD (Tier A):\n",
      "    Claims Volume: +76.7%\n",
      "    Monthly Claims: +76.7%\n",
      "    Median Price: +4.0%\n",
      "    Mean Price: -13.6%\n",
      "    Procedures per Claim: -21.5%\n",
      "\n",
      "  CLINICA PIEDRA AZUL, C.A. (Tier B):\n",
      "    Claims Volume: -3.4%\n",
      "    Monthly Claims: -3.4%\n",
      "    Median Price: -9.5%\n",
      "    Mean Price: +84.8%\n",
      "    Procedures per Claim: +3.6%\n",
      "\n",
      "  CLINICA VISTA ALEGRE C A (Tier B):\n",
      "    Claims Volume: +16.1%\n",
      "    Monthly Claims: +16.1%\n",
      "    Median Price: +40.8%\n",
      "    Mean Price: +34.4%\n",
      "    Procedures per Claim: +8.9%\n",
      "\n",
      "  COMERCIAL CIENTIFICA, C.A. (Tier A):\n",
      "    Claims Volume: +580.8%\n",
      "    Monthly Claims: +580.8%\n",
      "    Median Price: -24.3%\n",
      "    Mean Price: -64.3%\n",
      "    Procedures per Claim: -12.1%\n",
      "\n",
      "  GRUPO MEDICO VARGAS, C.A. (Tier B):\n",
      "    Claims Volume: -9.4%\n",
      "    Monthly Claims: -9.4%\n",
      "    Median Price: -46.6%\n",
      "    Mean Price: -28.1%\n",
      "    Procedures per Claim: -21.1%\n",
      "\n",
      "  SERVICIOS CLINICOS U.M.Q. NUEVA CARACAS , C.A (Tier C):\n",
      "    Claims Volume: -14.7%\n",
      "    Monthly Claims: -14.7%\n",
      "    Median Price: -2.9%\n",
      "    Mean Price: -4.9%\n",
      "    Procedures per Claim: +17.3%\n",
      "\n",
      "Underperformer Clinics (2):\n",
      "\n",
      "  CENTRO DIAGNOSTICO DOCENTE LAS MERCEDES, C.A. (Tier B):\n",
      "    Claims Volume: -57.9%\n",
      "    Monthly Claims: -57.9%\n",
      "    Median Price: +141.7%\n",
      "    Mean Price: +54.9%\n",
      "    Procedures per Claim: +6.9%\n",
      "\n",
      "  CENTRO MEDICO LOIRA, C.A. (Tier B):\n",
      "    Claims Volume: -34.8%\n",
      "    Monthly Claims: -34.8%\n",
      "    Median Price: +28.9%\n",
      "    Mean Price: +4.8%\n",
      "    Procedures per Claim: +4.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_140251/324503956.py:40: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  comparison_months = pd.date_range(\n"
     ]
    }
   ],
   "source": [
    "# Part 1.2: Before vs. After Joining Network (Normalized Time Frames)\n",
    "\n",
    "# Define analysis window (3 months before and after joining)\n",
    "ANALYSIS_WINDOW = pd.DateOffset(months=3)\n",
    "\n",
    "\n",
    "def analyze_clinic_performance(clinic_name):\n",
    "    \"\"\"\n",
    "    Analyzes clinic performance before and after joining network.\n",
    "    Compares same months across years to account for seasonality.\n",
    "    \"\"\"\n",
    "    \n",
    "    clinic_data = CLINICS_IN_RED.get(clinic_name)\n",
    "    if not clinic_data:\n",
    "        return None\n",
    "        \n",
    "    # Get join date\n",
    "    join_dates = [pd.to_datetime(d) for d in clinic_data['join_date'].values() if d]\n",
    "    if not join_dates:\n",
    "        return None\n",
    "    join_date = min(join_dates)\n",
    "    \n",
    "    # Get clinic's last transaction date in 2024\n",
    "    clinic_last_date = df_aggregated[\n",
    "        (df_aggregated['CLINIC'] == clinic_name) & \n",
    "        (df_aggregated['DATE'].dt.year == 2024)\n",
    "    ]['DATE'].max()\n",
    "    \n",
    "    if pd.isnull(clinic_last_date):\n",
    "        return None\n",
    "    \n",
    "    # Define comparison periods\n",
    "    after_start = join_date\n",
    "    after_end = clinic_last_date\n",
    "    \n",
    "    before_start = after_start - pd.DateOffset(years=1)\n",
    "    before_end = after_end - pd.DateOffset(years=1)\n",
    "    \n",
    "    # Get months to compare\n",
    "    comparison_months = pd.date_range(\n",
    "        after_start, \n",
    "        after_end, \n",
    "        freq='M'\n",
    "    ).month.unique()\n",
    "    \n",
    "    # Create masks for before and after periods\n",
    "    after_mask = (\n",
    "        (df_aggregated['CLINIC'] == clinic_name) &\n",
    "        (df_aggregated['DATE'] >= after_start) &\n",
    "        (df_aggregated['DATE'] <= after_end)\n",
    "    )\n",
    "    \n",
    "    before_mask = (\n",
    "        (df_aggregated['CLINIC'] == clinic_name) &\n",
    "        (df_aggregated['DATE'] >= before_start) &\n",
    "        (df_aggregated['DATE'] <= before_end) &\n",
    "        (df_aggregated['DATE'].dt.month.isin(comparison_months))  # Same months as after period\n",
    "    )\n",
    "    \n",
    "    # Get claims for both periods\n",
    "    after_claims = df_aggregated[after_mask].copy()\n",
    "    before_claims = df_aggregated[before_mask].copy()\n",
    "    \n",
    "    if len(after_claims) == 0 or len(before_claims) == 0:\n",
    "        return None\n",
    "        \n",
    "    # Calculate metrics for each period\n",
    "    metrics = {}\n",
    "    for period, claims in [('Before', before_claims), ('After', after_claims)]:\n",
    "        metrics[period] = {\n",
    "            'Claims': len(claims),\n",
    "            'Claims per Month': len(claims) / len(comparison_months),\n",
    "            'Median Price': claims['PAID_USD'].median(),\n",
    "            'Mean Price': claims['PAID_USD'].mean(),\n",
    "            'Total Paid': claims['PAID_USD'].sum(),\n",
    "            'Unique Procedures': len(set([item for sublist in claims['PROCEDURES'] for item in sublist])),\n",
    "            'Procedures per Claim': claims['PROCEDURES'].apply(len).mean()\n",
    "        }\n",
    "    \n",
    "    # Calculate percentage changes\n",
    "    changes = {\n",
    "        'Claims Volume': ((metrics['After']['Claims'] / metrics['Before']['Claims']) - 1) * 100,\n",
    "        'Monthly Claims': ((metrics['After']['Claims per Month'] / metrics['Before']['Claims per Month']) - 1) * 100,\n",
    "        'Median Price': ((metrics['After']['Median Price'] / metrics['Before']['Median Price']) - 1) * 100,\n",
    "        'Mean Price': ((metrics['After']['Mean Price'] / metrics['Before']['Mean Price']) - 1) * 100,\n",
    "        'Procedures per Claim': ((metrics['After']['Procedures per Claim'] / metrics['Before']['Procedures per Claim']) - 1) * 100\n",
    "    }\n",
    "    \n",
    "    # Determine performance category based on changes\n",
    "    score = 0\n",
    "    \n",
    "    # Volume score: +1 if volume increased by 10%, -1 if decreased by 10%\n",
    "    score += 1 if changes['Monthly Claims'] > 10 else -1 if changes['Monthly Claims'] < -10 else 0\n",
    "    \n",
    "    # Price score: +1 if prices decreased by 5%, -1 if increased by 5%\n",
    "    avg_price_change = (changes['Median Price'] + changes['Mean Price']) / 2\n",
    "    score += 1 if avg_price_change < -5 else -1 if avg_price_change > 5 else 0\n",
    "    \n",
    "    # Procedure diversity score: +1 if procedures per claim increased by 10%, -1 if decreased by 10%\n",
    "    score += 1 if changes['Procedures per Claim'] > 10 else -1 if changes['Procedures per Claim'] < -10 else 0\n",
    "    \n",
    "    performance = \"Overperformer\" if score >= 2 else \"Underperformer\" if score <= -2 else \"As Expected\"\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'changes': changes,\n",
    "        'performance': performance,\n",
    "        'tier': clinic_data.get('tier', 'Unknown'),\n",
    "        'comparison_period': {\n",
    "            'before': (before_start.strftime('%Y-%m-%d'), before_end.strftime('%Y-%m-%d')),\n",
    "            'after': (after_start.strftime('%Y-%m-%d'), after_end.strftime('%Y-%m-%d')),\n",
    "            'months_compared': sorted(comparison_months.tolist())\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Analyze all clinics\n",
    "clinic_performances = {}\n",
    "for clinic in CLINICS_IN_RED:\n",
    "    result = analyze_clinic_performance(clinic)\n",
    "    if result:\n",
    "        clinic_performances[clinic] = result\n",
    "\n",
    "# Print results\n",
    "print(\"\\nClinic Performance Analysis After Joining Network\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Group clinics by performance category\n",
    "performance_categories = {\n",
    "    \"Overperformer\": [],\n",
    "    \"As Expected\": [],\n",
    "    \"Underperformer\": []\n",
    "}\n",
    "\n",
    "for clinic, data in clinic_performances.items():\n",
    "    performance_categories[data['performance']].append((clinic, data))\n",
    "\n",
    "# Print results by category\n",
    "for category, clinics in performance_categories.items():\n",
    "    print(f\"\\n{category} Clinics ({len(clinics)}):\")\n",
    "    for clinic, data in clinics:\n",
    "        print(f\"\\n  {clinic} (Tier {data['tier']}):\")\n",
    "        for metric, value in data['changes'].items():\n",
    "            print(f\"    {metric}: {value:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tier-Based Performance Comparison\n",
      "--------------------------------------------------\n",
      "\n",
      "Tier A:\n",
      "\n",
      "  IN-Network Metrics:\n",
      "    Claims Volume: 15,659.00\n",
      "    Clinics: 5.00\n",
      "    Claims per Clinic: 3,131.80\n",
      "    Median Price: 1,587.00\n",
      "    Mean Price: 3,510.58\n",
      "    Price Range: $12.00 - $145,506.00\n",
      "    Unique Procedures per Clinic: 67.80\n",
      "    Procedures per Claim: 1.84\n",
      "\n",
      "  OUT-Network Metrics:\n",
      "    Claims Volume: 2,085.00\n",
      "    Clinics: 2.00\n",
      "    Claims per Clinic: 1,042.50\n",
      "    Median Price: 3,015.00\n",
      "    Mean Price: 4,779.18\n",
      "    Price Range: $75.00 - $116,685.00\n",
      "    Unique Procedures per Clinic: 71.50\n",
      "    Procedures per Claim: 2.46\n",
      "\n",
      "  Comparison (IN vs OUT):\n",
      "    Claims per Clinic: +200.4%\n",
      "    Median Price: -47.4%\n",
      "    Mean Price: -26.5%\n",
      "    Procedures per Claim: -25.1%\n",
      "\n",
      "Tier B:\n",
      "\n",
      "  IN-Network Metrics:\n",
      "    Claims Volume: 7,743.00\n",
      "    Clinics: 10.00\n",
      "    Claims per Clinic: 774.30\n",
      "    Median Price: 1,144.00\n",
      "    Mean Price: 2,396.15\n",
      "    Price Range: $32.00 - $130,000.00\n",
      "    Unique Procedures per Clinic: 22.50\n",
      "    Procedures per Claim: 2.07\n",
      "\n",
      "  OUT-Network Metrics:\n",
      "    Claims Volume: 926.00\n",
      "    Clinics: 1.00\n",
      "    Claims per Clinic: 926.00\n",
      "    Median Price: 724.00\n",
      "    Mean Price: 1,975.23\n",
      "    Price Range: $22.00 - $49,999.00\n",
      "    Unique Procedures per Clinic: 66.00\n",
      "    Procedures per Claim: 2.58\n",
      "\n",
      "  Comparison (IN vs OUT):\n",
      "    Claims per Clinic: -16.4%\n",
      "    Median Price: +58.0%\n",
      "    Mean Price: +21.3%\n",
      "    Procedures per Claim: -19.9%\n",
      "\n",
      "Tier C:\n",
      "\n",
      "  IN-Network Metrics:\n",
      "    Claims Volume: 2,909.00\n",
      "    Clinics: 3.00\n",
      "    Claims per Clinic: 969.67\n",
      "    Median Price: 844.00\n",
      "    Mean Price: 2,055.07\n",
      "    Price Range: $27.00 - $45,173.00\n",
      "    Unique Procedures per Clinic: 45.67\n",
      "    Procedures per Claim: 2.13\n",
      "\n",
      "  OUT-Network Metrics:\n",
      "    Claims Volume: 2,117.00\n",
      "    Clinics: 3.00\n",
      "    Claims per Clinic: 705.67\n",
      "    Median Price: 2,032.00\n",
      "    Mean Price: 3,387.38\n",
      "    Price Range: $25.00 - $52,901.00\n",
      "    Unique Procedures per Clinic: 43.00\n",
      "    Procedures per Claim: 2.28\n",
      "\n",
      "  Comparison (IN vs OUT):\n",
      "    Claims per Clinic: +37.4%\n",
      "    Median Price: -58.5%\n",
      "    Mean Price: -39.3%\n",
      "    Procedures per Claim: -6.8%\n"
     ]
    }
   ],
   "source": [
    "#### Part 1.3: Comparison Among Clinics In vs. Out of Network By Tier\n",
    "\n",
    "# Function to get tier metrics\n",
    "def calculate_tier_metrics(tier):\n",
    "    \"\"\"Calculates metrics for in-network and out-of-network clinics within a tier\"\"\"\n",
    "    \n",
    "    # Get in-network clinics for this tier\n",
    "    in_network = [\n",
    "        clinic for clinic, data in CLINICS_IN_RED.items() \n",
    "        if data.get('tier') == tier\n",
    "    ]\n",
    "    \n",
    "    # Get out-of-network comparison clinics for this tier\n",
    "    out_network = TIER_COMPARSION.get(tier, [])\n",
    "    \n",
    "    # Initialize results\n",
    "    results = {'IN': {}, 'OUT': {}}\n",
    "    \n",
    "    # Calculate metrics for each network status\n",
    "    for status, clinics in [('IN', in_network), ('OUT', out_network)]:\n",
    "        if not clinics:\n",
    "            continue\n",
    "            \n",
    "        # Get claims for these clinics\n",
    "        claims = df_aggregated[df_aggregated['CLINIC'].isin(clinics)]\n",
    "        \n",
    "        if len(claims) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Calculate metrics\n",
    "        results[status] = {\n",
    "            'Claims Volume': len(claims),\n",
    "            'Clinics': len(clinics),\n",
    "            'Claims per Clinic': len(claims) / len(clinics),\n",
    "            'Median Price': claims['PAID_USD'].median(),\n",
    "            'Mean Price': claims['PAID_USD'].mean(),\n",
    "            'Price Range': f\"${claims['PAID_USD'].min():,.2f} - ${claims['PAID_USD'].max():,.2f}\",\n",
    "            'Unique Procedures per Clinic': len(set([item for sublist in claims['PROCEDURES'] for item in sublist])) / len(clinics),\n",
    "            'Procedures per Claim': claims['PROCEDURES'].apply(len).mean()\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Get unique tiers from CLINICS_IN_RED\n",
    "tiers = set()\n",
    "for clinic_data in CLINICS_IN_RED.values():\n",
    "    if 'tier' in clinic_data:\n",
    "        tiers.add(clinic_data['tier'])\n",
    "\n",
    "# Analyze each tier\n",
    "print(\"\\nTier-Based Performance Comparison\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for tier in sorted(tiers):\n",
    "    print(f\"\\nTier {tier}:\")\n",
    "    metrics = calculate_tier_metrics(tier)\n",
    "    \n",
    "    for network_status in ['IN', 'OUT']:\n",
    "        if not metrics[network_status]:\n",
    "            print(f\"  No {network_status}-Network data available\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n  {network_status}-Network Metrics:\")\n",
    "        for metric, value in metrics[network_status].items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"    {metric}: {value:,.2f}\")\n",
    "            else:\n",
    "                print(f\"    {metric}: {value}\")\n",
    "                \n",
    "    # Calculate and print differences if both IN and OUT data exist\n",
    "    if metrics['IN'] and metrics['OUT']:\n",
    "        print(\"\\n  Comparison (IN vs OUT):\")\n",
    "        comparable_metrics = [\n",
    "            'Claims per Clinic',\n",
    "            'Median Price',\n",
    "            'Mean Price',\n",
    "            'Procedures per Claim'\n",
    "        ]\n",
    "        \n",
    "        for metric in comparable_metrics:\n",
    "            diff_pct = ((metrics['IN'][metric] / metrics['OUT'][metric]) - 1) * 100\n",
    "            print(f\"    {metric}: {diff_pct:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation Analysis:\n",
      "--------------------------------------------------\n",
      "                    PAID_USD  PROCEDURE_CLUSTER  INSURANCE_COVERAGE\n",
      "PAID_USD               1.000              0.192               0.106\n",
      "PROCEDURE_CLUSTER      0.192              1.000              -0.158\n",
      "INSURANCE_COVERAGE     0.106             -0.158               1.000\n",
      "\n",
      "Key Insights:\n",
      "\n",
      "Procedure Cluster Statistics:\n",
      "                   PAID_USD          INSURANCE_COVERAGE            \n",
      "                       mean   median               mean      median\n",
      "PROCEDURE_CLUSTER                                                  \n",
      "-1                 3257.100 1518.500        1101810.220 1000000.000\n",
      " 0                 4467.100 4437.500         134025.530  100000.000\n",
      " 1                 6815.150 5415.500         109798.590  100000.000\n",
      " 2                 1260.120  813.000         108537.220  100000.000\n",
      " 3                 4502.260 2791.000         112265.780  100000.000\n",
      " 4                 5011.670 3447.000         113415.980  100000.000\n",
      " 5                 1030.780  737.000         115663.740  100000.000\n",
      " 6                 2231.770 2307.500          97151.900  100000.000\n",
      " 7                 3250.010 3106.000         109389.670  100000.000\n",
      " 8                 2364.100 2369.000          96162.480  100000.000\n",
      " 9                 4031.700 3824.000          87157.890  100000.000\n",
      " 10                7950.620 5895.000          96428.570  100000.000\n",
      " 11                6986.390 7044.000         131631.070  100000.000\n",
      " 12                 913.530  888.500          96532.260  100000.000\n",
      " 13                2871.460 1813.500         116919.420  100000.000\n",
      " 14                1148.070  955.000         116836.280  100000.000\n",
      " 15                3527.300 3168.000         107380.950  100000.000\n",
      " 16                4269.730 2711.000         113670.030  100000.000\n",
      " 17                5801.320 5777.000         118787.530  100000.000\n",
      " 18                3802.650 3373.000         101111.110  100000.000\n",
      " 19                6614.230 6450.000         124383.950  100000.000\n",
      " 20                3685.210 3392.000         103075.000  100000.000\n",
      " 21                4229.590 4521.000         145317.460  200000.000\n",
      " 22                5817.190 5846.000         123090.910  100000.000\n",
      " 23                3883.610 3476.000         131250.000  100000.000\n",
      " 24                8260.490 7466.000         107958.580  100000.000\n",
      " 25               10167.590 9258.500         130063.290  100000.000\n",
      " 26                1860.910 1086.500         102686.570  100000.000\n",
      " 27                6339.710 6076.000          99915.610  100000.000\n",
      " 28                6022.920 5500.000         108615.380  100000.000\n",
      " 29                6066.890 5762.000         108146.260  100000.000\n",
      " 30                6453.530 5879.500         114080.460  100000.000\n",
      " 31                5659.470 5196.000          98758.820  100000.000\n",
      " 32                8253.510 7878.000          93085.500  100000.000\n",
      " 33                8608.360 7800.000          96482.410  100000.000\n",
      " 34                3826.010 3597.500          91983.470  100000.000\n",
      " 35                9944.450 7000.000          88395.060  100000.000\n",
      " 36                6846.960 6545.000         122500.000  100000.000\n",
      " 37                4414.890 4283.000         100930.230  100000.000\n",
      " 38                2376.820 2360.000         108769.230  100000.000\n",
      " 39                5602.870 5536.000         112270.270  100000.000\n",
      " 40                7535.320 7338.000          98474.580   50000.000\n",
      " 41                5092.880 4948.000         119617.490  100000.000\n",
      " 42                1484.310 1017.500          96574.070  100000.000\n",
      " 43                2674.420 2550.000         130479.450  100000.000\n",
      " 44                6323.070 6813.000         129142.860  100000.000\n",
      " 45                2752.440 2764.000         117226.280  100000.000\n",
      " 46                5597.280 5495.000         107196.650  100000.000\n",
      " 47                6864.760 6874.000         117076.920  100000.000\n",
      " 48                6481.590 5240.000         111850.780  100000.000\n",
      " 49                6968.580 6199.000         120225.230  100000.000\n",
      "\n",
      "Warning: Could not complete insurance coverage analysis: Bin labels must be one fewer than the number of bin edges\n",
      "This might be due to insufficient variation in coverage values.\n"
     ]
    }
   ],
   "source": [
    "def analyze_correlations(df):\n",
    "    \"\"\"Analyzes correlations between key metrics\"\"\"\n",
    "    \n",
    "    # First, ensure we have the insurance coverage data\n",
    "    df_with_coverage = df.merge(\n",
    "        df_normalized[['ID', 'INSURANCE_COVERAGE']], \n",
    "        on='ID', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Define columns we want to analyze\n",
    "    available_columns = ['PAID_USD', 'PROCEDURE_CLUSTER']\n",
    "    if 'INSURANCE_COVERAGE' in df_with_coverage.columns:\n",
    "        available_columns.append('INSURANCE_COVERAGE')\n",
    "    \n",
    "    # Calculate correlations only for available columns\n",
    "    corr_matrix = df_with_coverage[available_columns].corr()\n",
    "    \n",
    "    print(\"\\nCorrelation Analysis:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(corr_matrix.round(3))\n",
    "    \n",
    "    print(\"\\nKey Insights:\")\n",
    "    \n",
    "    # Create a multi-level column structure for cluster statistics\n",
    "    cluster_stats_columns = pd.MultiIndex.from_product([['PAID_USD', 'INSURANCE_COVERAGE'], ['mean', 'median']])\n",
    "    cluster_stats = pd.DataFrame(columns=cluster_stats_columns)\n",
    "    \n",
    "    # Fill payment statistics\n",
    "    payment_stats = df_with_coverage.groupby('PROCEDURE_CLUSTER')['PAID_USD'].agg(['mean', 'median']).round(2)\n",
    "    cluster_stats[('PAID_USD', 'mean')] = payment_stats['mean']\n",
    "    cluster_stats[('PAID_USD', 'median')] = payment_stats['median']\n",
    "    \n",
    "    # Fill insurance coverage statistics if available\n",
    "    if 'INSURANCE_COVERAGE' in df_with_coverage.columns:\n",
    "        coverage_stats = df_with_coverage.groupby('PROCEDURE_CLUSTER')['INSURANCE_COVERAGE'].agg(['mean', 'median']).round(2)\n",
    "        cluster_stats[('INSURANCE_COVERAGE', 'mean')] = coverage_stats['mean']\n",
    "        cluster_stats[('INSURANCE_COVERAGE', 'median')] = coverage_stats['median']\n",
    "    \n",
    "    print(\"\\nProcedure Cluster Statistics:\")\n",
    "    print(cluster_stats)\n",
    "    \n",
    "    # Only do insurance coverage analysis if the column exists and has valid data\n",
    "    if 'INSURANCE_COVERAGE' in df_with_coverage.columns and df_with_coverage['INSURANCE_COVERAGE'].notna().any():\n",
    "        # Remove zeros and create bins\n",
    "        valid_coverage = df_with_coverage[df_with_coverage['INSURANCE_COVERAGE'] > 0]\n",
    "        \n",
    "        try:\n",
    "            # Create bins with handling for duplicates\n",
    "            df_with_coverage['COVERAGE_BIN'] = pd.qcut(\n",
    "                valid_coverage['INSURANCE_COVERAGE'], \n",
    "                q=5, \n",
    "                labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'],\n",
    "                duplicates='drop'\n",
    "            )\n",
    "            \n",
    "            coverage_stats = df_with_coverage.groupby('COVERAGE_BIN').agg({\n",
    "                'PAID_USD': ['mean', 'median', 'count'],\n",
    "                'PROCEDURE_CLUSTER': 'nunique'\n",
    "            }).round(2)\n",
    "            \n",
    "            coverage_stats.columns = [\n",
    "                'Mean Payment', 'Median Payment', 'Claim Count', \n",
    "                'Unique Procedure Types'\n",
    "            ]\n",
    "            \n",
    "            print(\"\\nPayment Statistics by Insurance Coverage Level:\")\n",
    "            print(coverage_stats)\n",
    "            \n",
    "            # Calculate price ratios (amount paid vs coverage) for non-zero coverage\n",
    "            valid_coverage['PRICE_RATIO'] = (\n",
    "                valid_coverage['PAID_USD'] / \n",
    "                valid_coverage['INSURANCE_COVERAGE']\n",
    "            )\n",
    "            \n",
    "            ratio_stats = valid_coverage.groupby('COVERAGE_BIN')['PRICE_RATIO'].agg([\n",
    "                'mean', 'median'\n",
    "            ]).round(3)\n",
    "            \n",
    "            print(\"\\nPrice to Coverage Ratio by Coverage Level:\")\n",
    "            print(ratio_stats)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nWarning: Could not complete insurance coverage analysis: {str(e)}\")\n",
    "            print(\"This might be due to insufficient variation in coverage values.\")\n",
    "    else:\n",
    "        print(\"\\nNote: Insurance coverage analysis skipped - no valid coverage data available\")\n",
    "\n",
    "# Apply clustering to procedures\n",
    "procedure_clusters = cluster_procedures(df_aggregated['PROCEDURES'])\n",
    "df_aggregated['PROCEDURE_CLUSTER'] = df_aggregated['PROCEDURES'].apply(\n",
    "    lambda x: procedure_clusters.get(tuple(x), -1)\n",
    ")\n",
    "\n",
    "# Run correlation analysis\n",
    "analyze_correlations(df_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extended Analysis Results\n",
      "==================================================\n",
      "\n",
      "1. Medical Specialty Analysis\n",
      "------------------------------\n",
      "\n",
      "Top 10 Specialties by Volume:\n",
      "                           count     mean   median       std  network_rate\n",
      "SPECIALTY                                                                 \n",
      "MEDICINA INTERNA           36330 1961.160  914.000  3455.650         0.030\n",
      "TRAUMATOLOGIA              17045 4075.430 2779.000  4421.540         0.040\n",
      "CIRUGIA GENERAL             6457 5066.780 4769.000  3576.010         0.050\n",
      "PEDIATRIA                   5796 2805.360  996.000  6996.550         0.060\n",
      "OFTALMOLOGIA                3850 2334.720 2309.000   901.060         0.060\n",
      "OBSTETRICIA                 2994 4105.340 4413.000  1511.410         0.020\n",
      "OTORRINOLARINGOLOGIA        2745 4344.190 4765.000  2722.500         0.040\n",
      "ONCOLOGIA                   2370 7994.610 5115.000 11524.140         0.040\n",
      "UROLOGIA                    2118 5171.820 4354.000  3954.670         0.040\n",
      "TRAUMATOLOGIA ORTOPEDISTA   1756 4493.240 2629.500  5438.190         0.030\n",
      "\n",
      "Network Impact Analysis:\n",
      "\n",
      "Top 5 Specialties with Largest Price Reductions in Network:\n",
      "                          price_change_pct\n",
      "IN_RED                                    \n",
      "SPECIALTY                                 \n",
      "CIRUGIA PEDIATRICA                  38.630\n",
      "ONCOLOGIA                           25.980\n",
      "TRAUMATOLOGIA ORTOPEDISTA            8.810\n",
      "NEUMONOLOGIA                         7.610\n",
      "OBSTETRICIA                         -0.160\n",
      "\n",
      "2. Demographics Analysis\n",
      "------------------------------\n",
      "\n",
      "Metrics by Age Group:\n",
      "           Claims  Avg_Cost  Network_Rate  Avg_Procedures\n",
      "AGE_GROUP                                                \n",
      "0-18        28702  2103.630         0.040           2.190\n",
      "19-35       17817  2907.970         0.040           2.200\n",
      "36-50       19304  3424.330         0.040           2.250\n",
      "51-65       19236  4481.460         0.030           2.260\n",
      "65+         15425  4793.660         0.040           2.240\n",
      "\n",
      "3. Treatment Pattern Analysis\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_140251/365011376.py:99: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  'Claims': df_extended.groupby('AGE_GROUP').size(),\n",
      "/tmp/ipykernel_140251/365011376.py:100: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  'Avg_Cost': df_extended.groupby('AGE_GROUP')['PAID_USD'].mean().round(2),\n",
      "/tmp/ipykernel_140251/365011376.py:101: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  'Network_Rate': df_extended.groupby('AGE_GROUP')['IN_RED'].mean().round(2),\n",
      "/tmp/ipykernel_140251/365011376.py:102: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  'Avg_Procedures': df_extended.groupby('AGE_GROUP')['PROCEDURES'].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Treatment Clusters by Volume:\n",
      "                   Claims  Avg_Cost  Network_Rate  \\\n",
      "TREATMENT_CLUSTER                                   \n",
      "1                   49739  3667.130         0.000   \n",
      "0                   27152  1204.820         0.060   \n",
      "2                    7523  6998.520         0.070   \n",
      "3                    6783  4252.910         0.060   \n",
      "4                    3958  3786.260         0.140   \n",
      "\n",
      "                                              Common_Treatments  \n",
      "TREATMENT_CLUSTER                                                \n",
      "1                                                            []  \n",
      "0                                     [Tratamiento Ambulatorio]  \n",
      "2                  [Tratamiento Quirúrgico con Hospitalización]  \n",
      "3                             [Tratamiento con Hospitalización]  \n",
      "4                          [Tratamiento Quirúrgico Ambulatorio]  \n",
      "\n",
      "4. Business Line Analysis\n",
      "------------------------------\n",
      "\n",
      "Metrics by Business Line:\n",
      "               Claims  Avg_Cost  Network_Rate  Avg_Procedures\n",
      "BUSINESS_LINE                                                \n",
      "33               6229  1961.960         0.050           2.850\n",
      "71              79521  3579.690         0.040           2.210\n",
      "72              15333  3081.620         0.030           2.070\n",
      "\n",
      "5. Cross-Analysis: Average Cost by Specialty and Business Line\n",
      "------------------------------\n",
      "\n",
      "Top 5 Most Expensive Specialty-Business Line Combinations:\n",
      "BUSINESS_LINE  SPECIALTY             \n",
      "71             CIRUGIA CARDIOVASCULAR   15581.670\n",
      "               CARDIOLOGIA INFANTIL     12710.900\n",
      "72             CIRUGIA CARDIOVASCULAR   11562.000\n",
      "33             CIRUGIA DE TORAX          9373.000\n",
      "71             NUTRICIONISTA             8886.400\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kjain/.local/lib/python3.13/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (16) found smaller than n_clusters (30). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "### Part 2: Extended Analysis Using Additional Variables\n",
    "\n",
    "def analyze_extended_metrics():\n",
    "    \"\"\"Comprehensive analysis using additional variables from original dataset\"\"\"\n",
    "    \n",
    "    # Read original dataset\n",
    "    df_original = pd.read_csv('data.csv', encoding='utf-8', low_memory=False)\n",
    "    \n",
    "    # Merge with aggregated data\n",
    "    df_extended = df_aggregated.merge(\n",
    "        df_original[[\n",
    "            'CONCATENADO',  # This is our ID\n",
    "            'especialidad',\n",
    "            'edad',\n",
    "            'tipo de poliza',\n",
    "            'Producto',\n",
    "            'tratamiento',\n",
    "            'sucursal',\n",
    "            'Categoría',\n",
    "            'ramo'\n",
    "        ]],\n",
    "        left_on='ID',\n",
    "        right_on='CONCATENADO',\n",
    "        how='left'\n",
    "    ).rename(columns={\n",
    "        'especialidad': 'SPECIALTY',\n",
    "        'edad': 'AGE',\n",
    "        'tipo de poliza': 'POLICY_TYPE',\n",
    "        'Producto': 'PRODUCT',\n",
    "        'tratamiento': 'TREATMENT',\n",
    "        'sucursal': 'BRANCH',\n",
    "        'Categoría': 'CATEGORY',\n",
    "        'ramo': 'BUSINESS_LINE'\n",
    "    })\n",
    "    \n",
    "    # Convert IN_RED to numeric (True -> 1, False -> 0)\n",
    "    df_extended['IN_RED'] = df_extended['IN_RED'].astype(int)\n",
    "    \n",
    "    print(\"\\nExtended Analysis Results\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Medical Specialty Analysis\n",
    "    print(\"\\n1. Medical Specialty Analysis\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Count and financial metrics separately\n",
    "    specialty_counts = df_extended.groupby('SPECIALTY').size().sort_values(ascending=False)\n",
    "    specialty_financials = df_extended.groupby('SPECIALTY')['PAID_USD'].agg([\n",
    "        'mean', 'median', 'std'\n",
    "    ]).round(2)\n",
    "    \n",
    "    # Now IN_RED is numeric, so mean calculation will work\n",
    "    specialty_network = df_extended.groupby('SPECIALTY')['IN_RED'].mean().round(2)\n",
    "    \n",
    "    # Combine metrics\n",
    "    specialty_metrics = pd.concat([\n",
    "        specialty_counts.rename('count'),\n",
    "        specialty_financials,\n",
    "        specialty_network.rename('network_rate')\n",
    "    ], axis=1)\n",
    "    \n",
    "    print(\"\\nTop 10 Specialties by Volume:\")\n",
    "    print(specialty_metrics.head(10))\n",
    "    \n",
    "    # Network impact by specialty\n",
    "    print(\"\\nNetwork Impact Analysis:\")\n",
    "    network_impact = df_extended.pivot_table(\n",
    "        values='PAID_USD',\n",
    "        index='SPECIALTY',\n",
    "        columns='IN_RED',\n",
    "        aggfunc=['mean', 'count']\n",
    "    ).round(2)\n",
    "    \n",
    "    # Calculate price changes where we have both in and out of network data\n",
    "    network_impact['price_change_pct'] = (\n",
    "        (network_impact[('mean', 1)] - network_impact[('mean', 0)]) / \n",
    "        network_impact[('mean', 0)] * 100\n",
    "    ).round(2)\n",
    "    \n",
    "    print(\"\\nTop 5 Specialties with Largest Price Reductions in Network:\")\n",
    "    valid_changes = network_impact[\n",
    "        network_impact['price_change_pct'].notna() & \n",
    "        (network_impact[('count', 1)] >= 10) &  # Minimum sample size\n",
    "        (network_impact[('count', 0)] >= 10)\n",
    "    ]\n",
    "    print(valid_changes.nlargest(5, 'price_change_pct')[['price_change_pct']])\n",
    "    \n",
    "    # 2. Demographics Analysis\n",
    "    print(\"\\n2. Demographics Analysis\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Age analysis\n",
    "    df_extended['AGE'] = pd.to_numeric(df_extended['AGE'], errors='coerce')\n",
    "    age_bins = [0, 18, 35, 50, 65, float('inf')]\n",
    "    age_labels = ['0-18', '19-35', '36-50', '51-65', '65+']\n",
    "    df_extended['AGE_GROUP'] = pd.cut(df_extended['AGE'], bins=age_bins, labels=age_labels)\n",
    "    \n",
    "    age_metrics = pd.DataFrame({\n",
    "        'Claims': df_extended.groupby('AGE_GROUP').size(),\n",
    "        'Avg_Cost': df_extended.groupby('AGE_GROUP')['PAID_USD'].mean().round(2),\n",
    "        'Network_Rate': df_extended.groupby('AGE_GROUP')['IN_RED'].mean().round(2),\n",
    "        'Avg_Procedures': df_extended.groupby('AGE_GROUP')['PROCEDURES'].apply(\n",
    "            lambda x: np.mean([len(p) for p in x])\n",
    "        ).round(2)\n",
    "    })\n",
    "    \n",
    "    print(\"\\nMetrics by Age Group:\")\n",
    "    print(age_metrics)\n",
    "    \n",
    "    # 3. Treatment Analysis\n",
    "    print(\"\\n3. Treatment Pattern Analysis\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Spanish stop words list\n",
    "    spanish_stop_words = [\n",
    "        'de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas'\n",
    "    ]\n",
    "    \n",
    "    # Cluster treatments using NLP\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words=spanish_stop_words,\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=1000\n",
    "    )\n",
    "    \n",
    "    # Handle NaN values in treatments\n",
    "    treatments_text = df_extended['TREATMENT'].fillna('')\n",
    "    treatment_vectors = vectorizer.fit_transform(treatments_text)\n",
    "    \n",
    "    n_clusters = min(len(df_extended) // 20, 30)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    df_extended['TREATMENT_CLUSTER'] = kmeans.fit_predict(treatment_vectors)\n",
    "    \n",
    "    # Calculate metrics by treatment cluster\n",
    "    treatment_metrics = pd.DataFrame({\n",
    "        'Claims': df_extended.groupby('TREATMENT_CLUSTER').size(),\n",
    "        'Avg_Cost': df_extended.groupby('TREATMENT_CLUSTER')['PAID_USD'].mean().round(2),\n",
    "        'Network_Rate': df_extended.groupby('TREATMENT_CLUSTER')['IN_RED'].mean().round(2),\n",
    "        'Common_Treatments': df_extended.groupby('TREATMENT_CLUSTER')['TREATMENT'].agg(\n",
    "            lambda x: x.value_counts().head(3).index.tolist()\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    print(\"\\nTop 5 Treatment Clusters by Volume:\")\n",
    "    print(treatment_metrics.nlargest(5, 'Claims'))\n",
    "    \n",
    "    # 4. Business Line Analysis\n",
    "    print(\"\\n4. Business Line Analysis\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    business_metrics = pd.DataFrame({\n",
    "        'Claims': df_extended.groupby('BUSINESS_LINE').size(),\n",
    "        'Avg_Cost': df_extended.groupby('BUSINESS_LINE')['PAID_USD'].mean().round(2),\n",
    "        'Network_Rate': df_extended.groupby('BUSINESS_LINE')['IN_RED'].mean().round(2),\n",
    "        'Avg_Procedures': df_extended.groupby('BUSINESS_LINE')['PROCEDURES'].apply(\n",
    "            lambda x: np.mean([len(p) for p in x])\n",
    "        ).round(2)\n",
    "    })\n",
    "    \n",
    "    print(\"\\nMetrics by Business Line:\")\n",
    "    print(business_metrics)\n",
    "    \n",
    "    # 5. Cross-Analysis\n",
    "    print(\"\\n5. Cross-Analysis: Average Cost by Specialty and Business Line\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    cross_analysis = pd.pivot_table(\n",
    "        df_extended,\n",
    "        values='PAID_USD',\n",
    "        index='SPECIALTY',\n",
    "        columns='BUSINESS_LINE',\n",
    "        aggfunc='mean'\n",
    "    ).round(2)\n",
    "    \n",
    "    print(\"\\nTop 5 Most Expensive Specialty-Business Line Combinations:\")\n",
    "    flat_cross = cross_analysis.unstack()\n",
    "    print(flat_cross.nlargest(5))\n",
    "    \n",
    "    return {\n",
    "        'specialty_metrics': specialty_metrics,\n",
    "        'age_metrics': age_metrics,\n",
    "        'treatment_metrics': treatment_metrics,\n",
    "        'business_metrics': business_metrics,\n",
    "        'cross_analysis': cross_analysis\n",
    "    }\n",
    "\n",
    "# Run the extended analysis\n",
    "extended_results = analyze_extended_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
